{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MidasTask2-c.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxdtXSyLvjue"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgv8gMcGiC8Q"
      },
      "source": [
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize,Resize ,CenterCrop ,Grayscale\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "    return datasets\n",
        "m = [0.485, 0.456, 0.406]\n",
        "s = [0.229, 0.224, 0.225]\n",
        "dataset = ImageFolder(r\"/content/gdrive/MyDrive/Datasets/mnistTask\", transform=Compose([Resize(256),\n",
        "        CenterCrop(224),ToTensor(),Normalize(                      \n",
        "                         mean = m,\n",
        "                         std = s\n",
        "                     )  ]))\n",
        "print(len(dataset))\n",
        "datasets = train_val_dataset(dataset)\n",
        "print(len(datasets['train']))\n",
        "print(len(datasets['val']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTw04yyRijEr"
      },
      "source": [
        "import cv2                \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt                        \n",
        "%matplotlib inline    \n",
        "dataloaders = {x:DataLoader(datasets[x],16, shuffle=True, num_workers=0) for x in ['train','val']}\n",
        "x,y = next(iter(dataloaders['train']))\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "import torchvision\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001) \n",
        "\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "imshow(out , title = classes+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMezbQstingQ"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtceKyvPioL1"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,32,3,padding =1)\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32,64,3,padding =1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(128)\n",
        "        #self.conv3 = nn.Conv2d(128,256,3,padding =1)\n",
        "        #self.conv3_bn = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(56 * 56 * 64, 512) #28*28*256\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n",
        "        #x = self.pool(F.relu(self.conv3_bn(self.conv3(x))))\n",
        "        x= x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x= self.fc1(x)\n",
        "        x= self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_scratch_mnist = Net()\n",
        "if use_cuda:\n",
        "    model_scratch_mnist.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5gPmaDBis1s"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_scratch = nn.CrossEntropyLoss()\n",
        "optimizer_scratch = optim.Adam(model_scratch_mnist.parameters() , lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jPUFi-biv-Y"
      },
      "source": [
        "import time\n",
        "n_epochs_stop = 5\n",
        "epochs_no_improve = 0\n",
        "\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \n",
        "    since = time.time()\n",
        "    valid_loss_min = np.Inf \n",
        "    running_corrects = 0\n",
        "    \n",
        "    for epoch in range(1 , n_epochs+1):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out,target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            \n",
        "            \n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['val']):\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "          \n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds  == target.data)\n",
        "\n",
        "        epoch_acc = running_corrects.double() / len(datasets['val'])\n",
        "    \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tEpoc Accuracy: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss,\n",
        "            epoch_acc\n",
        "            ))\n",
        "        \n",
        "        if valid_loss < valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving the model'.format(valid_loss_min, valid_loss))\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            epochs_no_improve = 0\n",
        "            valid_loss_min = valid_loss \n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == n_epochs_stop:\n",
        "              print('Early stopping!')\n",
        "              time_elapsed = time.time() - since\n",
        "              return model\n",
        "              print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "            \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buSkRSHBi1Zc"
      },
      "source": [
        "model_scratch_mnist = train(15, dataloaders, model_scratch_mnist, optimizer_scratch, \n",
        "                      criterion_scratch, use_cuda, r'/content/gdrive/MyDrive/Saved models/model_scratch_mnistTask.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMffqFIxi-o3"
      },
      "source": [
        "\n",
        "model_scratch_mnist.load_state_dict(torch.load('/content/gdrive/MyDrive/Saved models/model_scratch_mnistTask.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83MujXJ8jAnU"
      },
      "source": [
        "import idx2numpy\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "file_image = '/content/gdrive/MyDrive/Datasets/train-images.idx3-ubyte'\n",
        "file_label = '/content/gdrive/MyDrive/Datasets/t10k-labels.idx1-ubyte'\n",
        "X_test = idx2numpy.convert_from_file(file_image)\n",
        "X_test = torch.stack([torch.from_numpy(np.array(i)) for i in X_test])\n",
        "X_test = X_test.reshape((-1, 1, 28, 28))\n",
        "X_test = torch.tensor(X_test)\n",
        "Y_test = idx2numpy.convert_from_file(file_label)\n",
        "Y_test = Y_test.reshape(Y_test.shape[0], 1)\n",
        "Y_test = torch.tensor(Y_test)\n",
        "\n",
        "class CustomTensorDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, tensors, transform=None):\n",
        "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
        "        self.tensors = tensors\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[0][index]\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        y = self.tensors[1][index]\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.tensors[0].size(0)\n",
        "\n",
        "\n",
        "def imshow(img, title=''):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.title(title)\n",
        "    plt.imshow(np.transpose( img.numpy(), (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "test_dataset_normal = CustomTensorDataset(tensors=(X_test,Y_test), transform=Compose([Resize(256), CenterCrop(224),ToTensor()])))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset_normal, batch_size=16)\n",
        "\n",
        "#outputs = model_scratch_mnist(X_test) #fix this"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xRYeVkpjB2R"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model_scratch_mnist(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JhdRDsxjDPF"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(10):#4\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsqS82FsjFeR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sdL5gKCqseM"
      },
      "source": [
        "#with pre trained model from 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XQH8o8JqwwG"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,32,3,padding =1)\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32,128,3,padding =1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(128)\n",
        "        #self.conv3 = nn.Conv2d(128,256,3,padding =1)\n",
        "        #self.conv3_bn = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(56 * 56 * 128, 1000) #28*28*256\n",
        "        self.fc2 = nn.Linear(1000, 62)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n",
        "        #x = self.pool(F.relu(self.conv3_bn(self.conv3(x))))\n",
        "        x= x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x= self.fc1(x)\n",
        "        x= self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_scratch1_imported = Net()\n",
        "if use_cuda:\n",
        "    model_scratch1_imported.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgGFQHosp6jp"
      },
      "source": [
        "for param in model_scratch1_imported.parameters():\n",
        "  param.require_grad = False\n",
        "fc = nn.Sequential(\n",
        "    nn.Linear((56 * 56 * 128, 800),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    \n",
        "    nn.Linear(800,10),\n",
        "    nn.LogSoftmax(dim=1)\n",
        "    \n",
        ")\n",
        "model_scratch1_imported.classifier = fc\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model_scratch1_imported.classifier.parameters(), lr=0.003)\n",
        "if use_cuda:\n",
        "    model_scratch1_imported.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn0ocamQrcjb"
      },
      "source": [
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize,Resize ,CenterCrop ,Grayscale\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "    return datasets\n",
        "m = [0.485, 0.456, 0.406]\n",
        "s = [0.229, 0.224, 0.225]\n",
        "dataset = ImageFolder(r\"/content/gdrive/MyDrive/Datasets/mnistTask\", transform=Compose([Resize(256),\n",
        "        CenterCrop(224),ToTensor(),Normalize(                      \n",
        "                         mean = m,\n",
        "                         std = s\n",
        "                     )  ]))\n",
        "print(len(dataset))\n",
        "datasets = train_val_dataset(dataset)\n",
        "print(len(datasets['train']))\n",
        "print(len(datasets['val']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK4z42LhuXI_"
      },
      "source": [
        "import cv2                \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt                        \n",
        "%matplotlib inline    \n",
        "dataloaders = {x:DataLoader(datasets[x],16, shuffle=True, num_workers=0) for x in ['train','val']}\n",
        "x,y = next(iter(dataloaders['train']))\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "import torchvision\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001) \n",
        "\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "imshow(out , title = classes+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_oLGk3iublN"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_scratch = nn.CrossEntropyLoss()\n",
        "optimizer_scratch = optim.Adam(model_scratch.classifier.parameters() , lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oryki06kvCQ7"
      },
      "source": [
        "model_transfer =  train(20, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_scratch1_imported_for_c.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}