{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MidasTask2-b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4HW0P44hE82",
        "outputId": "2f40336d-f076-4251-ed4e-d0b230b85f9c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxn6g0HO5rDV"
      },
      "source": [
        "!pip3 install -q idx2numpy\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWJQGmIkhrg2",
        "outputId": "59481b89-bc2d-495e-d60d-dcbcd5a51e7f"
      },
      "source": [
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize,Resize ,CenterCrop ,Grayscale\n",
        "from torch.utils.data import DataLoader\n",
        "import idx2numpy\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "import torchvision\n",
        "\n",
        "\n",
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "    return datasets\n",
        "\n",
        "\n",
        "file_image = '/content/gdrive/MyDrive/Datasets/train-images.idx3-ubyte'\n",
        "file_label = '/content/gdrive/MyDrive/Datasets/train-labels.idx1-ubyte'\n",
        "X_train = idx2numpy.convert_from_file(file_image)\n",
        "X_train = torch.stack([torch.from_numpy(np.array(i)) for i in X_train])\n",
        "X_train = X_train.reshape((-1, 1, 28, 28))\n",
        "X_train = torch.tensor(X_train)\n",
        "Y_train = idx2numpy.convert_from_file(file_label)\n",
        "Y_train = Y_train.reshape(Y_train.shape[0], 1)\n",
        "Y_train = torch.tensor(Y_train)\n",
        "\n",
        "class CustomTensorDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, tensors, transform=None):\n",
        "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
        "        self.tensors = tensors\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[0][index]\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        y = self.tensors[1][index]\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.tensors[0].size(0)\n",
        "\n",
        "\n",
        "def imshow(img, title=''):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.title(title)\n",
        "    plt.imshow(np.transpose( img.numpy(), (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "m = [0.485, 0.456, 0.406]\n",
        "s = [0.229, 0.224, 0.225]\n",
        "\n",
        "Dataset = CustomTensorDataset(tensors=(X_train,Y_train), transform=Compose([Resize(256), CenterCrop(224),ToTensor(),Normalize(                      \n",
        "                         mean = m,\n",
        "                         std = s\n",
        "                     ) ])) #)\n",
        "datasets = train_val_dataset(Dataset)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0dMiLxuEyz16",
        "outputId": "0794ccae-e10f-4e16-91cb-232437e79737"
      },
      "source": [
        "file_image = '/content/gdrive/MyDrive/Datasets/train-images.idx3-ubyte'\n",
        "file_label = '/content/gdrive/MyDrive/Datasets/t10k-labels.idx1-ubyte'\n",
        "X_test = idx2numpy.convert_from_file(file_image)\n",
        "X_test = torch.stack([torch.from_numpy(np.array(i)) for i in X_test])\n",
        "X_test = X_test.reshape((-1, 1, 28, 28))\n",
        "X_test = torch.tensor(X_test)\n",
        "Y_test = idx2numpy.convert_from_file(file_label)\n",
        "Y_test = Y_test.reshape(Y_test.shape[0], 1)\n",
        "Y_test = torch.tensor(Y_test)\n",
        "\n",
        "class CustomTensorDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, tensors, transform=None):\n",
        "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
        "        self.tensors = tensors\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[0][index]\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        y = self.tensors[1][index]\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.tensors[0].size(0)\n",
        "\n",
        "\n",
        "def imshow(img, title=''):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.title(title)\n",
        "    plt.imshow(np.transpose( img.numpy(), (1, 2, 0)), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "datasets['test'] = CustomTensorDataset(tensors=(X_test,Y_test), transform=Compose([Resize(256), CenterCrop(224),ToTensor()])) #)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c7cd4e481518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustomTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() takes from 2 to 3 positional arguments but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj79GBjsz_wV"
      },
      "source": [
        "dataloaders = {x:DataLoader(datasets[x],20, shuffle=True, num_workers=0) for x in ['train','val','test']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baEALsAc05HF"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC8Ei1ON2dL8"
      },
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92NBaUHA11Mn"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,32,3,padding =1)\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32,128,3,padding =1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(128)\n",
        "        #self.conv3 = nn.Conv2d(128,256,3,padding =1)\n",
        "        #self.conv3_bn = nn.BatchNorm2d(256)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(56 * 56 * 128, 1000) #28*28*256\n",
        "        self.fc2 = nn.Linear(1000, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n",
        "        #x = self.pool(F.relu(self.conv3_bn(self.conv3(x))))\n",
        "        x= x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x= self.fc1(x)\n",
        "        x= self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_scratch1_imported = Net()\n",
        "if use_cuda:\n",
        "    model_scratch1_imported.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bj2vkhc16wy"
      },
      "source": [
        "for param in model_scratch1_imported.parameters():\n",
        "  param.require_grad = False\n",
        "fc = nn.Sequential(\n",
        "    nn.Linear((56 * 56 * 128, 800),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    \n",
        "    nn.Linear(800,10),\n",
        "    nn.LogSoftmax(dim=1)\n",
        "    \n",
        ")\n",
        "model_scratch1_imported.classifier = fc\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model_scratch1_imported.classifier.parameters(), lr=0.003)\n",
        "if use_cuda:\n",
        "    model_scratch1_imported.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8It_abm2ETr"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_scratch = nn.CrossEntropyLoss()\n",
        "optimizer_scratch = optim.Adam(model_scratch.classifier.parameters() , lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrmHayrZ2K_-"
      },
      "source": [
        "import time\n",
        "n_epochs_stop = 5\n",
        "epochs_no_improve = 0\n",
        "\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \n",
        "    since = time.time()\n",
        "    valid_loss_min = np.Inf \n",
        "    running_corrects = 0\n",
        "    \n",
        "    for epoch in range(1 , n_epochs+1):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out,target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            \n",
        "            \n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['val']):\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "          \n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds  == target.data)\n",
        "\n",
        "        epoch_acc = running_corrects.double() / len(datasets['val'])\n",
        "    \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tEpoc Accuracy: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss,\n",
        "            epoch_acc\n",
        "            ))\n",
        "        \n",
        "        if valid_loss < valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving the model'.format(valid_loss_min, valid_loss))\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            epochs_no_improve = 0\n",
        "            valid_loss_min = valid_loss \n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == n_epochs_stop:\n",
        "              print('Early stopping!')\n",
        "              time_elapsed = time.time() - since\n",
        "              return model\n",
        "              print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
        "    \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "            \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXcHOf-c2Ol0"
      },
      "source": [
        "model_transfer =  train(20, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_scratch1_imported_for_c.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}